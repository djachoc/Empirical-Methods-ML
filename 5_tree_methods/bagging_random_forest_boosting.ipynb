{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liberal-distributor",
   "metadata": {},
   "source": [
    "<h1> Main Idea</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-click",
   "metadata": {},
   "source": [
    "**Bagging**, **random forests**, and **boosting** involves producing multiple trees which are then combined to yield a single consensus prediction. We will see that combining a large number of trees can often result in dramatic improvements in prediction accuracy, at the expense of some loss in interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threaded-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image\n",
    "from six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# This function creates images of tree models using pydot\n",
    "def print_tree(estimator, features, class_names=None, filled=True):\n",
    "    tree = estimator\n",
    "    names = features\n",
    "    color = filled\n",
    "    classn = class_names\n",
    "    \n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(estimator, out_file=dot_data, feature_names=features, class_names=classn, filled=filled)\n",
    "    (graph,) = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-reggae",
   "metadata": {},
   "source": [
    "```\n",
    "Boston.csv\n",
    "\n",
    "A data frame containing 506 observations on housing values of suburbs in Boston and the following 14 variables:\n",
    "\n",
    "crim    per capita crime rate by town.\n",
    "zn      proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "indus   proportion of non-retail business acres per town.\n",
    "chas    Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "nox     nitrogen oxides concentration (parts per 10 million).\n",
    "rm      average number of rooms per dwelling.\n",
    "age     proportion of owner-occupied units built prior to 1940.boxcox 21\n",
    "dis     weighted mean of distances to five Boston employment centres.\n",
    "rad     index of accessibility to radial highways.\n",
    "tax     full-value property-tax rate per $10,000.\n",
    "ptratio pupil-teacher ratio by town.\n",
    "black   1000(Bk − 0.63)2 where Bk is the proportion of blacks by town.\n",
    "lstat   lower status of the population (percent).\n",
    "medv    median value of owner-occupied homes in $1000s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handed-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "boston_df = pd.read_csv('https://r-data.pmagunia.com/system/files/datasets/dataset-70319.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stopped-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_df.drop('medv', axis=1)\n",
    "y = boston_df.medv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-recruitment",
   "metadata": {},
   "source": [
    "<h2>Bagging</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-essex",
   "metadata": {},
   "source": [
    "Recall that given a set of $n$ independent observations $Z_{1}, \\ldots, Z_{n}$, each with variance $\\sigma^{2}$, the variance of the mean $\\bar{Z}$ of the observations is given by $\\sigma^{2} / n .$ In other words, averaging a set of observations reduces variance. Hence a natural way to reduce the variance and hence increase the prediction accuracy of a statistical learning method is to take many training sets from the population, build a separate prediction model using each training set, and average the resulting predictions. In other words, we could calculate $\\hat{f}^{1}(x), \\hat{f}^{2}(x), \\ldots, \\hat{f}^{B}(x)$ using $B$ separate training sets, and average them in order to obtain a single low-variance statistical learning model, given by\n",
    "$$\n",
    "\\hat{f}_{\\text {avg }}(x)=\\frac{1}{B} \\sum_{b=1}^{B} \\hat{f}^{b}(x)\n",
    "$$\n",
    "Of course, this is not practical because we generally do not have access to multiple training sets. Instead, we can [**bootstrap**](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)), by taking repeated samples from the (single) training data set. In this approach we generate $B$ different bootstrapped training data sets. We then train our method on the $b$th bootstrapped training set in order to get $\\hat{f}^{* b}(x)$, and finally average all the predictions, to obtain\n",
    "$$\n",
    "\\hat{f}_{\\mathrm{bag}}(x)=\\frac{1}{B} \\sum_{b=1}^{B} \\hat{f}^{* b}(x)\n",
    "$$\n",
    "This is called [**bagging**](https://en.wikipedia.org/wiki/Bootstrap_aggregating), i.e., from _**b**ootstrap **agg**regat**ing**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-equity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9502a4e39ec24487a7cf539da1356e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05r\\x00\\x00\\x03:\\x08\\x06\\x00\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import IPython.display as display\n",
    "## Read images from file\n",
    "img1 = open('img/bootstrap.png', 'rb').read()\n",
    "img2 = open('img/bagging.png', 'rb').read()\n",
    "## Create image widgets. You can use layout of ipywidgets only with widgets.\n",
    "## Set image variable, image format and dimension.\n",
    "wi1 = widgets.Image(value=img1, format='png', width=500, height=600)\n",
    "wi2 = widgets.Image(value=img2, format='png', width=500, height=600)\n",
    "## Side by side thanks to HBox widgets\n",
    "sidebyside = widgets.HBox([wi1, wi2])\n",
    "## Finally, show.\n",
    "display.display(sidebyside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "macro-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "regbag = BaggingRegressor(base_estimator=DecisionTreeRegressor(),oob_score=True,\n",
    "                          n_estimators=100, random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aboriginal-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624f2733dad046859251a6e2e83a6080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x04\\x98\\x00\\x00\\x03V\\x08\\x06\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Read images from file\n",
    "img3 = open('img/bagging_prediction.png', 'rb').read()\n",
    "## Create image widgets. You can use layout of ipywidgets only with widgets.\n",
    "## Set image variable, image format and dimension.\n",
    "wi3 = widgets.Image(value=img3, format='png', width=400, height=500)\n",
    "## Side by side thanks to HBox widgets\n",
    "pic = widgets.HBox([wi3])\n",
    "## Finally, show.\n",
    "display.display(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instant-civilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y_test')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pred = regbag.predict(X_test)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.scatter(pred, y_test, label='medv')\n",
    "plt.plot([0, 1], [0, 1], '--k', transform=plt.gca().transAxes)\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pleasant-indian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.09091723529412"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-signal",
   "metadata": {},
   "source": [
    "<h3><em>Out-of-Bag</em> Error Estimation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-click",
   "metadata": {},
   "source": [
    "Recall that the key to bagging is that trees are repeatedly fit to bootstrapped subsets of the observations. <ins>One can show that on average, each bagged tree makes use of around two-thirds of the observations</ins>:\n",
    "<blockquote>\n",
    "If there are $n$ rows in the training data set. Then, the probability of not picking a row in a random draw is\n",
    "\n",
    "$$\n",
    "\\frac{n-1}{n}\n",
    "$$\n",
    "    \n",
    "Using _sampling-with-replacement_ the probability of not picking $n$ rows in random draws is\n",
    "\n",
    "$$\n",
    "\\left(\\frac{n-1}{n}\\right)^n\n",
    "$$\n",
    "In the limit as $n\\rightarrow\\infty$ one has\n",
    "    \n",
    "$$\n",
    "\\lim_{n\\rightarrow\\infty}\\left(1-\\frac{1}{n}\\right)^n=\\exp{(-1)}=0.368\n",
    "$$\n",
    "</blockquote>\n",
    "\n",
    "The remaining one-third of the observations not used to fit a given bagged tree are referred to as the __out-of-bag (OOB)__ observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "patient-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35c1762b53b4f8b918825cd8402d8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\xd2\\x00\\x00\\x03^\\x08\\x06\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Read images from file (because this is binary, maybe you can find how to use ByteIO) but this is more easy\n",
    "img4 = open('img/OOB_evaluation.png', 'rb').read()\n",
    "## Create image widgets. You can use layout of ipywidgets only with widgets.\n",
    "## Set image variable, image format and dimension.\n",
    "wi4 = widgets.Image(value=img4, format='png', width=600, height=700)\n",
    "## Side by side thanks to HBox widgets\n",
    "pic = widgets.HBox([wi4])\n",
    "## Finally, show.\n",
    "display.display(pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-lightning",
   "metadata": {},
   "source": [
    "We can predict the response for the $i$th observation using each of the trees in which that observation was OOB. This will yield around $B/3$ predictions for the $i$th observation. In order to obtain a single prediction for the $i$th observation:\n",
    "\n",
    "👉🏼 Regression: We can average these predicted responses\n",
    "\n",
    "👉🏼 Classification: We can take a majority vote.\n",
    "\n",
    "This leads to a single OOB prediction for the $i$th observation.\n",
    "\n",
    "📝 An OOB prediction can be obtained in this way for each of the $n$ observations and then the `r2_score` can be calculated for the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"oob score is: \", regbag.oob_score_) # The oob score is an estimate of the r2 score of the ensemble regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-pressure",
   "metadata": {},
   "source": [
    "<h2>Random Forest</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-rings",
   "metadata": {},
   "source": [
    "Random forests provide an improvement over bagged trees by way of a small tweak that decorrelates the trees. As in bagging, we build a number of decision trees on bootstrapped training samples. But when building these decision trees, <ins>each time a split in a tree is considered, a random sample of $m$ predictors is chosen as split candidates from the full set of $p$ predictors</ins>.\n",
    "\n",
    "👉🏼 The split is allowed to use only one of those $m$ predictors.\n",
    "\n",
    "👉🏼 A fresh sample of $m$ predictors is taken at each split, and typically we choose $m \\approx \\sqrt{p}$ - that is, the number of predictors considered at each split is approximately equal to the square root of the total number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt as sqrt\n",
    "# There are 13 features in the dataset\n",
    "print(X.shape)\n",
    "print(sqrt(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest: using 4 features\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regrf = RandomForestRegressor(max_features=4, random_state=42)\n",
    "regrf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-cattle",
   "metadata": {},
   "source": [
    "📝 The main difference between bagging and random forests is the choice of predictor subset size $m$. For instance, if a random forest is built using\n",
    "$m = p$, then this amounts simply to bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regrf.predict(X_test)\n",
    "\n",
    "plt.scatter(pred, y_test, label='medv')\n",
    "plt.plot([0, 1], [0, 1], '--k', transform=plt.gca().transAxes)\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-popularity",
   "metadata": {},
   "source": [
    "<h3>Variance Importance Measures</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-essay",
   "metadata": {},
   "source": [
    "Although the collection of trees is much more difficult to interpret than a single tree, one can obtain an overall summary of the importance of each predictor using the $RSS$ (for regression trees) or the <em>Gini index</em> (for classification trees). In the case of regression trees, we can record the total amount that the $RSS$ is decreased due to splits over a given predictor, averaged over all $B$ trees. A large value indicates an important predictor. Similarly, in the context of classification trees, we can add up the total amount that the <em>Gini index</em> is decreased by splits over a given predictor, averaged over all $B$ trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests: using 4 features\n",
    "regrf2 = RandomForestRegressor(max_features=4, random_state=42)\n",
    "regrf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import FeatureImportances\n",
    "viz = FeatureImportances(regrf2)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-mathematics",
   "metadata": {},
   "source": [
    "The variables with the largest _mean_ decrease in $RSS$ are `rm` and `lstat`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-grove",
   "metadata": {},
   "source": [
    "<h2>Boosting</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-manual",
   "metadata": {},
   "source": [
    "Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each\n",
    "copy, and then combining all of the trees in order to create a single predictive model. Notably, each tree is built on a bootstrap data set, independent of the other trees. Boosting works in a similar way, except that the <ins>trees are grown sequentially</ins>: each tree is grown using information from previously grown trees.\n",
    "\n",
    "🔔 Boosting does not involve bootstrap sampling; instead each tree is fit on a modified version of the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-carpet",
   "metadata": {},
   "source": [
    "***\n",
    "**Algorithm**: <ins>_Boosting_ for Regression Trees</ins>\n",
    "\n",
    "1. Set $\\hat{f}(x)=0$ and $r_{i}=y_{i}$ for all $i$ in the training set.\n",
    "2. For $b=1,2, \\ldots, B$(=`n_estimators`), repeat:\\\n",
    "(a) Fit a tree $\\hat{f}^{b}$ with $d$ splits (`max_leaf_nodes=`$d+1$ terminal nodes ) to the training data $(X, r)$.\\\n",
    "(b) Update $\\hat{f}$ by adding in a shrunken version ($\\lambda$=`learning_rate`) of the new tree:\n",
    "$$\n",
    "\\hat{f}(x) \\leftarrow \\hat{f}(x)+\\lambda \\hat{f}^{b}(x)\n",
    "$$\n",
    "(c) Update the residuals,\n",
    "$$\n",
    "r_{i} \\leftarrow r_{i}-\\lambda \\hat{f}^{b}\\left(x_{i}\\right)\n",
    "$$\n",
    "3. Output the boosted model,\n",
    "$$\n",
    "\\hat{f}(x)=\\sum_{b=1}^{B} \\lambda \\hat{f}^{b}(x) .\n",
    "$$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-columbia",
   "metadata": {},
   "source": [
    "📝 The number $d$ of splits in each tree controls the complexity of the boosted ensemble. Often $d=1$ works well, in which case each tree is a _stump_, consisting of a single split (`max_depth=1`). In this case, the boosted ensemble is fitting an additive model, since each term involves only a single variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "regb = GradientBoostingRegressor(n_estimators=500,\n",
    "                                 learning_rate=0.01,\n",
    "                                 max_leaf_nodes=10,\n",
    "                                 random_state=42)\n",
    "regb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_train, regb.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = FeatureImportances(regb)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, regb.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
