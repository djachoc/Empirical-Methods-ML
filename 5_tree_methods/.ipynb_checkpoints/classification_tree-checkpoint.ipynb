{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advised-mattress",
   "metadata": {},
   "source": [
    "<h1>Classification Trees</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-salvation",
   "metadata": {},
   "source": [
    "```\n",
    "Carseats.csv\n",
    "A data frame containing observations on sales of child car seats at 400 different stores and the following 11 variables:\n",
    "\n",
    "Sales        Unit sales (in thousands) at each location\n",
    "CompPrice    Price charged by competitor at each location\n",
    "Income       Community income level (in thousands of dollars)\n",
    "Advertising  Local advertising budget for company at each location (in thousands of dollars)\n",
    "Population   Population size in region (in thousands)\n",
    "Price        Price company charges for car seats at each site\n",
    "ShelveLoc    A factor with levels Bad, Good and Medium indicating the quality of the shelving loca\u0002tion for the car seats at each site\n",
    "Age          Average age of the local population\n",
    "Education    Education level at each location\n",
    "Urban        A factor with levels No and Yes to indicate whether the store is in an urban or rural location\n",
    "US           A factor with levels No and Yes to indicate whether the store is in the US or not\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image\n",
    "from six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# This function creates images of tree models using pydot\n",
    "def print_tree(estimator, features, class_names=None, filled=True):\n",
    "    tree = estimator\n",
    "    names = features\n",
    "    color = filled\n",
    "    classn = class_names\n",
    "    \n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(estimator, out_file=dot_data, feature_names=features, class_names=classn, filled=filled)\n",
    "    (graph,) = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://r-data.pmagunia.com/system/files/datasets/dataset-11424.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the data\n",
    "\n",
    "df['High'] = df.Sales.map(lambda x: 1 if x>8 else 0)\n",
    "df.ShelveLoc = pd.factorize(df.ShelveLoc)[0]\n",
    "df.Urban = df.Urban.map({'No':0, 'Yes':1})\n",
    "df.US = df.US.map({'No':0, 'Yes':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Sales', 'High'], axis=1)\n",
    "y = df.High\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-exemption",
   "metadata": {},
   "source": [
    "<h2>The Basics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-vegetation",
   "metadata": {},
   "source": [
    "A classification tree is very similar to a regression tree, except that it is used to predict a qualitative response rather than a quantitative one, i.e., we predict that each observation belongs to the <em>most commonly occurring class</em> of training\n",
    "observations in the region to which it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-static",
   "metadata": {},
   "source": [
    "The task of growing a classification tree is quite similar to the task of growing a regression tree. Just as in the regression setting, we use recursive binary splitting to grow a classification tree. However, in the classification setting, $RSS$ cannot be used as a criterion for making the binary splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-parts",
   "metadata": {},
   "source": [
    "<ins>__Option 1__</ins>: Classification Error Rate\n",
    "\n",
    "Since we plan to assign an observation in a given region to the most commonly occurring error rate class of training observations in that region, the classification error rate is simply the fraction of the training observations in that region that do not belong to the most common class:\n",
    "\n",
    "$$E=1-\\max _{k}\\left(\\hat{p}_{m k}\\right)$$\n",
    "\n",
    "Here $\\hat{p}_{m k}$ represents the proportion of training observations in the $m$th region that are from the $k$ th class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(p):\n",
    "    return 1 - np.max([p, 1 - p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-assurance",
   "metadata": {},
   "source": [
    "<ins>__Option 2__</ins>: Gini Index\n",
    "\n",
    "The Gini index is defined by\n",
    "$$\n",
    "G=\\sum_{k=1}^{K} \\hat{p}_{m k}\\left(1-\\hat{p}_{m k}\\right)\n",
    "$$\n",
    "a measure of total variance across the $K$ classes. It is not hard to see that the Gini index takes on a small value if all of the $\\hat{p}_{m k}$ 's are close to zero or one. For this reason the Gini index is referred to as a measure of node purity-a small value indicates that a node contains predominantly observations from a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(p):\n",
    "    return 2*(p)*(1 - p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-chart",
   "metadata": {},
   "source": [
    "<ins>__Option 3__</ins>: Cross-Entropy\n",
    "\n",
    "$$\n",
    "D=-\\sum_{k=1}^{K} \\hat{p}_{m k} \\log \\hat{p}_{m k}\\left(\\frac{1}{2\\log(2)}\\right)\n",
    "$$\n",
    "\n",
    "Since $0 \\leq \\hat{p}_{m k} \\leq 1$, it follows that $0 \\leq-\\hat{p}_{m k} \\log \\hat{p}_{m k}$. One can show that the entropy will take on a value near zero if the $\\hat{p}_{m k}$ 's are all near zero or near one. Therefore, like the Gini index, the entropy will take on a small value if the $m$ th node is pure.\n",
    "\n",
    "üëâüèº In fact, it turns out that the Gini index and the entropy are quite similar numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    return (p*np.log((1-p)/p) - np.log(1 - p)) / (2*np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0.0, 1.0, 0.01)\n",
    "class_error_vals = [classification_error(i) for i in x]\n",
    "gini_vals = gini(x)\n",
    "entropy_vals = [entropy(i) if i != 0 else None for i in x]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot()\n",
    "\n",
    "for j, lab, c, in zip(\n",
    "    [class_error_vals, gini_vals, entropy_vals],\n",
    "    ['Class. Error Rate', 'Gini Index', 'Cross-entropy'],\n",
    "    ['red', 'blue', 'green']):\n",
    "    line = ax.plot(x, j, label=lab, linestyle='-', lw=3, color=c)\n",
    "\n",
    "ax.legend(loc='lower center', fancybox=True, shadow=False)\n",
    "\n",
    "plt.ylim([0, 0.52])\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('Impurity Index: E, G, D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-procedure",
   "metadata": {},
   "source": [
    "<h2>Example</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-therapy",
   "metadata": {},
   "source": [
    "The [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) from `sklearn` only options are the `gini` and the `entropy` impurity indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini',max_depth=6)\n",
    "clf_gini.fit(X_train, y_train)\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy',max_depth=6)\n",
    "clf_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, clf_gini.predict(X_train)))\n",
    "print(classification_report(y_train, clf_entropy.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = print_tree(clf_gini, features=X_train.columns, class_names=['No', 'Yes'])\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = print_tree(clf_entropy, features=X_train.columns, class_names=['No', 'Yes'])\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gini = clf_gini.predict(X_test)\n",
    "pred_entropy = clf_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision of the model using test data is 75%\n",
    "print(classification_report(y_test, pred_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision of the model using test data is 73%\n",
    "print(classification_report(y_test, pred_entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-integration",
   "metadata": {},
   "source": [
    "<h2>Choosing Hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Specify cross-validation generator, in this case (10 x 5CV)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10,random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    {'criterion': ['gini','entropy'], 'max_depth': range(2, 10)}\n",
    "]\n",
    "\n",
    "scoring = make_scorer(precision_score,greater_is_better=True)\n",
    "g_cv = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "              param_grid=param_grid,\n",
    "              scoring=scoring, cv=cv,n_jobs=-1)\n",
    "\n",
    "g_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(g_cv.cv_results_)\n",
    "results_df = results_df.sort_values(by=['rank_test_score'])\n",
    "results_df = (\n",
    "    results_df\n",
    "    .set_index(results_df[\"params\"].apply(\n",
    "        lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "    )\n",
    "    .rename_axis('params')\n",
    ")\n",
    "results_df[\n",
    "    ['params', 'rank_test_score', 'mean_test_score', 'std_test_score']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, g_cv.best_estimator_.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
