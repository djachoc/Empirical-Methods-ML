{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dealing with [*Missing* Data](https://en.wikipedia.org/wiki/Missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In most online _machine learning_ classes you are taught that when your data set is **incomplete** you can either:\n",
    "1. Erase the corresponding rows with missing cells; or\n",
    "2. _Impute_ (fill) the sample average of each column into those missing cells.\n",
    "\n",
    "It turns out that the second option would require stronger assumptions than the first. If the observations are **missing completely at random** and your sample is i.i.d., the first option is harmless for large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoding [Categorical Variables](https://en.wikipedia.org/wiki/Categorical_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» Consider the ```hprice3``` data set from the ```wooldridge``` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: wooldridge\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>StrVector with 1 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'hprice3'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.StrVector object at 0x7f605fb63a50> [RTYPES.STRSXP]\n",
       "R classes: ('character',)\n",
       "['hprice3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## installing the 'wooldridge' package if not previously installed\n",
    "%R if (!require(wooldridge)) install.packages('wooldridge')\n",
    "\n",
    "%R data(hprice3)\n",
    "\n",
    "## Obs:   321\n",
    "\n",
    "##  1. year                     1978, 1981\n",
    "##  2. age                      age of house\n",
    "##  3. agesq                    age^2\n",
    "##  4. nbh                      neighborhood, 1 to 6\n",
    "##  5. cbd                      dist. to central bus. dstrct, feet\n",
    "##  6. inst                     dist. to interstate, feet\n",
    "##  7. linst                    log(inst)\n",
    "##  8. price                    selling price\n",
    "##  9. rooms                    # rooms in house\n",
    "## 10. area                     square footage of house\n",
    "## 11. land                     square footage lot\n",
    "## 12. baths                    # bathrooms\n",
    "## 13. dist                     dist. from house to incin., feet\n",
    "## 14. ldist                    log(dist)\n",
    "## 15. lprice                   log(price)\n",
    "## 16. y81                      =1 if year = 1981\n",
    "## 17. larea                    log(area)\n",
    "## 18. lland                    log(land)\n",
    "## 19. linstsq                  linst^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "hprice3 = woo.dataWoo('hprice3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» Variables ```y81```, ```rooms```, and ```nbh``` are examples of <ins>categorical</ins> variables. In Econometrics, ```y81``` is called a standard dummy variable, ```rooms``` is called an _ordered_ categorical variable, ```nbh``` is called an _unordered_ categorical variable. Both ```rooms``` and ```nbh``` have _multiple_ categories. The fucntion ```as.factor()``` with option ```ordered=TRUE``` and ```ordered=FALSE``` (default) will allow us to handle them accordingly in all analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      y81             rooms             nbh       \n",
      " Min.   :0.0000   Min.   : 4.000   Min.   :0.000  \n",
      " 1st Qu.:0.0000   1st Qu.: 6.000   1st Qu.:0.000  \n",
      " Median :0.0000   Median : 7.000   Median :2.000  \n",
      " Mean   :0.4424   Mean   : 6.586   Mean   :2.209  \n",
      " 3rd Qu.:1.0000   3rd Qu.: 7.000   3rd Qu.:4.000  \n",
      " Max.   :1.0000   Max.   :10.000   Max.   :6.000  \n",
      " y81     rooms    nbh    \n",
      " 0:179   4 :  4   0:121  \n",
      " 1:142   5 : 30   1: 27  \n",
      "         6 : 96   2: 47  \n",
      "         7 :169   3:  7  \n",
      "         8 : 10   4: 60  \n",
      "         9 : 11   5: 27  \n",
      "         10:  1   6: 32  \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "attach(hprice3)\n",
    "no.factor <- data.frame(y81=y81,rooms=rooms,nbh=nbh)\n",
    "print(summary(no.factor))\n",
    "detach(hprice3)\n",
    "\n",
    "attach(hprice3)\n",
    "yes.factor <- data.frame(y81=factor(y81),rooms=factor(rooms,ordered=TRUE),nbh=factor(nbh,ordered=FALSE))\n",
    "print(summary(yes.factor))\n",
    "detach(hprice3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "no_factor = hprice3[['y81','rooms','nbh']]\n",
    "print(no_factor.dtypes)\n",
    "yes_factor = pd.DataFrame({'y81':hprice3['y81'],\n",
    "                           'rooms':hprice3['rooms'].astype('category'),\n",
    "                           'nbh':hprice3['nbh'].astype('category')})\n",
    "yes_factor.rooms.cat.set_categories(\n",
    "    new_categories = sorted(hprice3['rooms'].unique()), ordered = True, inplace = True)\n",
    "print(yes_factor.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» The default behavior in regression is to transformed ordered and unordered categorical variable with multiple categories into a set of $c-1$ dummy variables and include them as regressors, where $c$ represents the number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%R ols <- lm(lprice ~ lland + larea + I(log(cbd)) +as.factor(y81) + as.factor(rooms) + as.factor(nbh) +linst + linstsq + ldist + baths + age + agesq,data=hprice3)\n",
    "\n",
    "## installing the 'lmtest', 'sandwich' packages if not previously installed\n",
    "%R if (!require(lmtest)) install.packages('lmtest')\n",
    "%R if (!require(sandwich)) install.packages('sandwich')\n",
    "\n",
    "## turning 'off' scientific notation\n",
    "%R options(scipen = 999) \n",
    "\n",
    "## calculating standard t-statistics for 'significance'\n",
    "%R coeftest(ols, vcov = vcovHC, type = 'HC1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from numpy import log\n",
    "f = 'lprice ~ lland + larea + log(cbd) + C(y81) + C(rooms) + C(nbh) + linst + linstsq + ldist + baths + age + agesq'\n",
    "res = ols(formula=f,data=hprice3).fit(cov_type='HC1')\n",
    "print(res.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» In many machine learning algorithms you are required to provide the design (model) matrix, $\\mathbf{X}$ (*without* and intercept), and response vector, $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**<span style=\"color:green\">Exercise:</span>**: ```R``` - Use the ```model.matrix``` function to extract the design matrix _without_ an intercept from the previously created ```ols``` object and verify it contains 22 columns of regressors/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%R X <- model.matrix(ols)[,-1]\n",
    "%R print(dim(X))\n",
    "%R print(colnames(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "y,X = patsy.dmatrices(f, hprice3, return_type='dataframe')\n",
    "del X['Intercept']\n",
    "print(X.shape)\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "ðŸ“Œ ```R```: It is good practice to define categorical variables _outside_ the model formula/fitting. When doing this, one can easily change the 'base' category using the ```relevel()``` function along with the ```within()``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Including [Interaction Terms](https://en.wikipedia.org/wiki/Interaction_(statistics) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the previously fitted model we included ```linstsq``` and ```agesq``` as predictors. These correspond to the squared of the original predictors ```linst``` and ```age```. In economics we include such predictors to account for increasing/decreasing returns to scale in modelling. Since $\\texttt{linst}^2=\\texttt{linst}\\times\\texttt{linst}$ and $\\texttt{age}^2=\\texttt{age}\\times\\texttt{age}$, one can think of them as a specific type of interaction terms (products with themselves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ins>Example</ins>: Consider the following version of the previously estimated model\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\texttt{lprice}&=\\beta_0+\\beta_1\\texttt{lland}+\\beta_2\\texttt{larea}+ \\beta_3\\texttt{linst}+\\beta_4\\texttt{age}\\\\\n",
    "               & + \\beta_5\\texttt{linst}\\times\\texttt{age}+\\beta_6\\texttt{linst}^2+\\beta_7\\texttt{age}^2+e\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: estimating this new model\n",
    "%R ols.0 <- lm(lprice ~ lland + larea + linst + age + I(linst*age) + linstsq + agesq,data=hprice3)\n",
    "%R round(coef(ols.0),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'lprice ~ lland + larea + linst + age + I(linst*age) + linstsq + agesq'\n",
    "res_0 = ols(formula=f,data=hprice3).fit()\n",
    "\n",
    "import numpy as np\n",
    "np.round(res_0.params,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By defining $\\mathbf{x}=[\\texttt{lland},\\texttt{larea},\\texttt{linst},\\texttt{age}]^\\prime$, and Assumption MLR.4, one has\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E[\\texttt{lprice}|\\mathbf{x}]}{\\partial \\texttt{linst}}=\\beta_3+\\beta_5\\texttt{age}+2\\beta_6\\texttt{linst}.\n",
    "$$\n",
    "\n",
    "Then $\\beta_3$ represents the average price elasticty with respect to the distance from the highway for a home that is brand new ($\\texttt{age}=0$) and that is located 1 feet away from the highway ($\\texttt{linst}=\\log(\\texttt{inst})=0$, i.e., $\\texttt{inst}=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ðŸ’» Calculating the summary statistics for variables ```age``` and ```inst``` in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## printing summary statistics for 'age' and 'inst'\n",
    "%R print(summary(subset(hprice3,select=c('age','inst','linst'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hprice3[['age','inst','linst']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now consider the following alternative specification\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\texttt{lprice}&=\\delta_0+\\beta_1\\texttt{lland}+\\beta_2\\texttt{larea}+ \\delta_3\\texttt{linst}+\\delta_4\\texttt{age}\\\\\n",
    "               & + \\beta_5[\\texttt{linst}-\\mu_{\\texttt{linst}}]\\times[\\texttt{age}-\\mu_{\\texttt{age}}]+\\beta_6[\\texttt{linst}-\\mu_{\\texttt{linst}}]^2+\\beta_7[\\texttt{age}-\\mu_{\\texttt{age}}]^2+e.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In this case\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E[\\texttt{lprice}|\\mathbf{x}]}{\\partial \\texttt{linst}}=\\delta_3+\\beta_5[\\texttt{age}-\\mu_{\\texttt{age}}]+2\\beta_6[\\texttt{linst}-\\mu_{\\texttt{linst}}].\n",
    "$$\n",
    "\n",
    "Then $\\delta_3$ represents the average price elasticty with respect to the distance from the highway for a home that is 18 years old ($\\widehat{\\mu}_{\\texttt{age}}\\approx 18.01$) and that is located 16,442 feet away from the highway ($\\widehat{\\mu}_{\\texttt{inst}}\\approx 16,442$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: estimating this new 'version' model\n",
    "%R ols.1 <- lm(lprice ~ lland + larea + linst + age + I((linst-log(mean(inst)))*(age-mean(age))) + I((linst-log(mean(inst)))^2) + I((age-mean(age))^2),data=hprice3)\n",
    "\n",
    "## printing ols results up to 5 decimals\n",
    "%R round(data.frame(ols.0=coef(ols.0),ols.1=coef(ols.1)),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = hprice3[['age','inst','linst']].mean()\n",
    "f = 'lprice ~ lland + larea + linst + age + I((linst-log(m.loc[\"inst\"]))*(age-m.loc[\"age\"])) + I((linst-log(m.loc[\"inst\"]))**2) + I((age-m.loc[\"age\"])**2)'\n",
    "res_1 = ols(formula=f,data=hprice3).fit()\n",
    "\n",
    "import numpy as np\n",
    "pd.DataFrame({'ols.0':res_0.params,'ols.1':res_1.params})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "â‰ï¸ Is it a coincidence that some of the estimates are the same in both specifications? provide an algebraic explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beta Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why is standardization useful? It is easiest to start with the original OLS equation, with the variables in their original forms:\n",
    "\n",
    "$$\n",
    "y_{i}=\\widehat{\\beta}_{0}+\\widehat{\\beta}_{1} x_{i 1}+\\widehat{\\beta}_{2} x_{i 2}+\\ldots+\\widehat{\\beta}_{k} x_{i k}+\\hat{e}_{i}.\n",
    "$$\n",
    "\n",
    "We have included the observation subscript i to emphasize that our standardization is applied to all sample values. If we average the previous equation and use the fact that $\\{\\widehat{e}_i:i=1,\\ldots,n\\}$ has sample mean zero one has\n",
    "\n",
    "$$\n",
    "y_{i}-\\overline{y}=\\widehat{\\beta}_{1}\\left(x_{i 1}-\\overline{x}_{1}\\right)+\\widehat{\\beta}_{2}\\left(x_{i 2}-\\overline{x}_{2}\\right)+\\ldots+\\widehat{\\beta}_{k}\\left(x_{i k}-\\overline{x}_{k}\\right)+\\widehat{e}_{i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, let $\\widehat{\\sigma}_{y}$ be the sample standard deviation for the dependent variable, let $\\widehat{\\sigma}_{1}$ be the sample sd for $x_{1}$, let $\\widehat{\\sigma}_{2}$ be the sample standard deviation, ```sd()```, for $x_{2}$, and so on. Then, simple algebra gives the equation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left(y_{i}-\\overline{y}\\right) / \\widehat{\\sigma}_{y} &=\\left(\\widehat{\\sigma}_{1} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{1}\\left[\\left(x_{i 1}-\\overline{x}_{1}\\right) / \\widehat{\\sigma}_{1}\\right]+\\ldots \\\\ &+\\left(\\widehat{\\sigma}_{k} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{k}\\left[\\left(x_{i k}-\\overline{x}_{k}\\right) / \\widehat{\\sigma}_{k}\\right]+\\left(\\widehat{e}_{i} / \\widehat{\\sigma}_{y}\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now define $z_{i y}=\\left(y_{i}-\\overline{y}\\right) / \\widehat{\\sigma}_{y}$, $z_{i l}=\\left[\\left(x_{i l}-\\overline{x}_{l}\\right) / \\widehat{\\sigma}_{l}\\right]$, $\\widehat{b}_{l}=\\left(\\widehat{\\sigma}_{l} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{l}$ for $l=1,\\ldots,k$, and $\\widehat{\\varepsilon}_i=\\left(\\widehat{e}_{i} / \\widehat{\\sigma}_{y}\\right)$. Then\n",
    "\n",
    "$$\n",
    "z_{y}=\\widehat{b}_{1} z_{1}+\\widehat{b}_{2} z_{2}+\\ldots+\\widehat{b}_{k} z_{k}+\\widehat{\\varepsilon}_i.\n",
    "$$\n",
    "\n",
    "The new coefficients are\n",
    "\n",
    "$$\n",
    "\\widehat{b}_{j}=\\left(\\widehat{\\sigma}_{j} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{j} \\text { for } j=1, \\ldots, k.\n",
    "$$\n",
    "\n",
    "These $\\widehat{b}_{j}$ are traditionally called **standardized coefficients** or **beta coefficients**.\n",
    "\n",
    "âœðŸ½ If $x_l$ increases by one standard deviation, then $\\widehat{y}$ changes by $\\widehat{b}_l$ standard deviations. Thus, *we are measuring effects not in terms of the original units of $y$ or the $x_l$, but in standard deviation units*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## installing the 'lm.beta' package if not previously installed\n",
    "%R if (!require(lm.beta)) install.packages('lm.beta')\n",
    "\n",
    "%R coef(lm.beta(ols.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "f = 'lprice ~ lland + larea + linst + age + I((linst-log(m.loc[\"inst\"]))*(age-m.loc[\"age\"])) + I((linst-log(m.loc[\"inst\"]))**2) + I((age-m.loc[\"age\"])**2) - 1'\n",
    "y,X = patsy.dmatrices(f, hprice3, return_type='dataframe')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats.mstats import zscore\n",
    "\n",
    "print(sm.OLS(zscore(y),zscore(X)).fit().params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» Since each $x_l$ have been standardized, comparing the _magnitudes_ of the resulting beta coefficients is now useful. The ```age``` of the house seems to have the largest effect on the price of a home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ins>Pre-Processing in Machine Learning</ins>: In machine learning, standardizing (*re-centering* and *scaling*) predictors is commonly done before model fitting. No transformation is usually done to the outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%R X1 <- model.matrix(ols.1)[,-1]\n",
    "%R datos <- cbind(data.frame(lprice=hprice3$lprice),as.data.frame(X1))\n",
    "\n",
    "## installing the 'caret' package if not previously installed\n",
    "%R if (!require(caret)) install.packages('caret')\n",
    "\n",
    "%R modelo <- train(lprice ~ .,data = datos,method = 'lm',preProcess = c('scale', 'center'))\n",
    "\n",
    "%R coef(modelo$finalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm.OLS(y,np.c_[np.ones(X.shape[0]),zscore(X)]).fit().params)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
