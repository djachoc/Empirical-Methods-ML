{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dealing with [*Missing* Data](https://en.wikipedia.org/wiki/Missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In most online _machine learning_ classes you are taught that when your data set is **incomplete** you can either:\n",
    "1. Erase the corresponding rows with missing cells; or\n",
    "2. _Impute_ (fill) the sample average of each column into those missing cells.\n",
    "\n",
    "It turns out that the second option would require stronger assumptions than the first. If the observations are **missing completely at random** and your sample is i.i.d., the first option is harmless for large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoding [Categorical Variables](https://en.wikipedia.org/wiki/Categorical_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» Consider the ```hprice3``` data set from the ```wooldridge``` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## installing the 'wooldridge' package if not previously installed\n",
    "if (!require(wooldridge)) install.packages('wooldridge')\n",
    "\n",
    "data(hprice3)\n",
    "\n",
    "## Obs:   321\n",
    "\n",
    "##  1. year                     1978, 1981\n",
    "##  2. age                      age of house\n",
    "##  3. agesq                    age^2\n",
    "##  4. nbh                      neighborhood, 1 to 6\n",
    "##  5. cbd                      dist. to central bus. dstrct, feet\n",
    "##  6. inst                     dist. to interstate, feet\n",
    "##  7. linst                    log(inst)\n",
    "##  8. price                    selling price\n",
    "##  9. rooms                    # rooms in house\n",
    "## 10. area                     square footage of house\n",
    "## 11. land                     square footage lot\n",
    "## 12. baths                    # bathrooms\n",
    "## 13. dist                     dist. from house to incin., feet\n",
    "## 14. ldist                    log(dist)\n",
    "## 15. lprice                   log(price)\n",
    "## 16. y81                      =1 if year = 1981\n",
    "## 17. larea                    log(area)\n",
    "## 18. lland                    log(land)\n",
    "## 19. linstsq                  linst^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "hprice3 = woo.dataWoo('hprice3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» Variables ```y81```, ```rooms```, and ```nbh``` are examples of <ins>categorical</ins> variables. In Econometrics, ```y81``` is called a standard dummy variable, ```rooms``` is called an _ordered_ categorical variable, ```nbh``` is called an _unordered_ categorical variable. Both ```rooms``` and ```nbh``` have _multiple_ categories. The fucntion ```as.factor()``` with option ```ordered=TRUE``` and ```ordered=FALSE``` (default) will allow us to handle them accordingly in all analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## without using the 'as.factor' function\n",
    "attach(hprice3)\n",
    "no.factor <- data.frame(y81=y81,rooms=rooms,nbh=nbh)\n",
    "summary(no.factor)\n",
    "detach(hprice3)\n",
    "\n",
    "## using the 'factor' function\n",
    "attach(hprice3)\n",
    "yes.factor <- data.frame(y81=factor(y81),\n",
    "                         rooms=factor(rooms,ordered=TRUE),\n",
    "                         nbh=factor(nbh,ordered=FALSE)\n",
    "                         )\n",
    "summary(yes.factor)\n",
    "detach(hprice3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y81      int64\n",
      "rooms    int64\n",
      "nbh      int64\n",
      "dtype: object\n",
      "y81         int64\n",
      "rooms    category\n",
      "nbh      category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "no_factor = hprice3[['y81','rooms','nbh']]\n",
    "print(no_factor.dtypes)\n",
    "yes_factor = pd.DataFrame({'y81':hprice3['y81'],\n",
    "                           'rooms':hprice3['rooms'].astype('category'),\n",
    "                           'nbh':hprice3['nbh'].astype('category')})\n",
    "yes_factor.rooms.cat.set_categories(\n",
    "    new_categories = sorted(hprice3['rooms'].unique()), ordered = True, inplace = True)\n",
    "print(yes_factor.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "\n",
    "**<span style=\"color:green\">Exercise:</span>**: Plot a histogram of the variable ```rooms``` when it is not treated as a factor and when it is treated as an ```ordered=TRUE``` factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "hist(no.factor$rooms,main=\"(Non-Categorical) Rooms\",xlab=\"\",ylab=\"\")\n",
    "plot(yes.factor$rooms,main=\"(Ordered Categorical) Rooms\",xlab=\"\",ylab=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» The default behavior in regression is to transformed ordered and unordered categorical variable with multiple categories into a set of $c-1$ dummy variables and include them as regressors, where $c$ represents the number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ols <- lm(lprice ~ lland + larea + I(log(cbd)) +\n",
    "                   as.factor(y81) + as.factor(rooms) + as.factor(nbh) +\n",
    "                   linst + linstsq + ldist + baths + age + agesq,\n",
    "          data=hprice3)\n",
    "\n",
    "## installing the 'lmtest', 'sandwich' packages if not previously installed\n",
    "if (!require(lmtest)) install.packages('lmtest')\n",
    "if (!require(sandwich)) install.packages('sandwich')\n",
    "\n",
    "## turning 'off' scientific notation\n",
    "options(scipen = 999) \n",
    "\n",
    "## calculating standard t-statistics for 'significance'\n",
    "coeftest(ols, vcov = vcovHC, type = \"HC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» In many machine learning algorithms you are required to provide the design (model) matrix, $\\mathbf{X}$ (*without* and intercept), and response vector, $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**<span style=\"color:green\">Exercise:</span>**: Use the ```model.matrix``` function to extract the design matrix _without_ an intercept from the previously created ```ols``` object and verify it contains 22 columns of regressors/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "X <- model.matrix(ols)[,-1]\n",
    "dim(X)\n",
    "colnames(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "ðŸ“Œ It is good practice to define categorical variables _outside_ the model formula/fitting. When doing this, one can easily change the 'base' category using the ```relevel()``` function along with the ```within()``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**<span style=\"color:green\">Exercise:</span>**:\n",
    "1. Create a copy of the ```hprice3``` data frame, call it ```hprice3.copy``` that contains all the variables used in fitting the model ```ols``` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "hprice3.copy <- subset(hprice3,select=c(\"lprice\",\"lland\",\"larea\",\"cbd\",\n",
    "                                        \"y81\",\"rooms\",\"nbh\",\"linst\",\n",
    "                                        \"linstsq\",\"ldist\",\"baths\",\"age\",\"agesq\"))\n",
    "names(hprice3.copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "2. Add the variable ```lcbd``` which equals the natural logarithm of ```cbd``` and then drop ```cbd``` from ```hprice3.copy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "hprice3.copy$lcbd <- log(hprice3.copy$cbd)\n",
    "hprice3.copy <- subset(hprice3.copy,select=-c(cbd))\n",
    "names(hprice3.copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "3. Replace ```y81```, ```rooms```, and ```nbh``` by their factor versions in ```hprice3.copy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "hprice3.copy$y81 <- factor(hprice3.copy$y81)\n",
    "hprice3.copy$rooms <- factor(hprice3.copy$rooms,ordered=TRUE)\n",
    "hprice3.copy$nbh <- factor(hprice3.copy$nbh,ordered=FALSE)\n",
    "head(hprice3.copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "4. Make ```y81==1``` and ```nbh==3``` the base categories in ```hprice3.copy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "hprice3.copy <- within(hprice3.copy, y81 <- relevel(y81,ref=2))\n",
    "hprice3.copy <- within(hprice3.copy, nbh <- relevel(nbh,ref=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "5. Run a regression of ```lprice``` on all the other features in the ```hprice3.copy``` and report the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "ols.sim <- lm(lprice~.,data=hprice3.copy)\n",
    "coef(ols.sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Including [Interaction Terms](https://en.wikipedia.org/wiki/Interaction_(statistics) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the previously fitted model we included ```linstsq``` and ```agesq``` as predictors. These correspond to the squared of the original predictors ```linst``` and ```age```. In economics we include such predictors to account for increasing/decreasing returns to scale in modelling. Since $\\texttt{linst}^2=\\texttt{linst}\\times\\texttt{linst}$ and $\\texttt{age}^2=\\texttt{age}\\times\\texttt{age}$, one can think of them as a specific type of interaction terms (products with themselves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ins>Example</ins>: Consider the following version of the previously estimated model\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\texttt{lprice}&=\\beta_0+\\beta_1\\texttt{lland}+\\beta_2\\texttt{larea}+ \\beta_3\\texttt{linst}+\\beta_4\\texttt{age}\\\\\n",
    "               & + \\beta_5\\texttt{linst}\\times\\texttt{age}+\\beta_6\\texttt{linst}^2+\\beta_7\\texttt{age}^2+e\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: estimating this new model\n",
    "ols.0 <- lm(lprice ~ lland + larea + linst + age\n",
    "                     + I(linst*age) + linstsq + agesq,\n",
    "          data=hprice3)\n",
    "round(coef(ols.0),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By defining $\\mathbf{x}=[\\texttt{lland},\\texttt{larea},\\texttt{linst},\\texttt{age}]^\\prime$, and Assumption MLR.4, one has\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E[\\texttt{lprice}|\\mathbf{x}]}{\\partial \\texttt{linst}}=\\beta_3+\\beta_5\\texttt{age}+2\\beta_6\\texttt{linst}.\n",
    "$$\n",
    "\n",
    "Then $\\beta_3$ represents the average price elasticty with respect to the distance from the highway for a home that is brand new ($\\texttt{age}=0$) and that is located 1 feet away from the highway ($\\texttt{linst}=\\log(\\texttt{inst})=0$, i.e., $\\texttt{inst}=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ðŸ’» Calculating the summary statistics for variables ```age``` and ```inst``` in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## printing summary statistics for 'age' and 'inst'\n",
    "print(summary(subset(hprice3,select=c(\"age\",\"inst\",\"linst\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now consider the following alternative specification\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\texttt{lprice}&=\\delta_0+\\beta_1\\texttt{lland}+\\beta_2\\texttt{larea}+ \\delta_3\\texttt{linst}+\\delta_4\\texttt{age}\\\\\n",
    "               & + \\beta_5[\\texttt{linst}-\\mu_{\\texttt{linst}}]\\times[\\texttt{age}-\\mu_{\\texttt{age}}]+\\beta_6[\\texttt{linst}-\\mu_{\\texttt{linst}}]^2+\\beta_7[\\texttt{age}-\\mu_{\\texttt{age}}]^2+e.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In this case\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E[\\texttt{lprice}|\\mathbf{x}]}{\\partial \\texttt{linst}}=\\delta_3+\\beta_5[\\texttt{age}-\\mu_{\\texttt{age}}]+2\\beta_6[\\texttt{linst}-\\mu_{\\texttt{linst}}].\n",
    "$$\n",
    "\n",
    "Then $\\delta_3$ represents the average price elasticty with respect to the distance from the highway for a home that is 18 years old ($\\widehat{\\mu}_{\\texttt{age}}\\approx 18.01$) and that is located 16,442 feet away from the highway ($\\widehat{\\mu}_{\\texttt{inst}}\\approx 16,442$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: estimating this new 'version' model\n",
    "ols.1 <- lm(lprice ~ lland + larea + linst + age\n",
    "                     + I((linst-log(mean(inst)))*(age-mean(age)))\n",
    "                     + I((linst-log(mean(inst)))^2) + I((age-mean(age))^2),\n",
    "          data=hprice3)\n",
    "\n",
    "## printing ols results up to 5 decimals\n",
    "round(data.frame(ols.0=coef(ols.0),ols.1=coef(ols.1)),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "â‰ï¸ Is it a coincidence that some of the estimates are the same in both specifications? provide an algebraic explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beta Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why is standardization useful? It is easiest to start with the original OLS equation, with the variables in their original forms:\n",
    "\n",
    "$$\n",
    "y_{i}=\\widehat{\\beta}_{0}+\\widehat{\\beta}_{1} x_{i 1}+\\widehat{\\beta}_{2} x_{i 2}+\\ldots+\\widehat{\\beta}_{k} x_{i k}+\\hat{e}_{i}.\n",
    "$$\n",
    "\n",
    "We have included the observation subscript i to emphasize that our standardization is applied to all sample values. If we average the previous equation and use the fact that $\\{\\widehat{e}_i:i=1,\\ldots,n\\}$ has sample mean zero one has\n",
    "\n",
    "$$\n",
    "y_{i}-\\overline{y}=\\widehat{\\beta}_{1}\\left(x_{i 1}-\\overline{x}_{1}\\right)+\\widehat{\\beta}_{2}\\left(x_{i 2}-\\overline{x}_{2}\\right)+\\ldots+\\widehat{\\beta}_{k}\\left(x_{i k}-\\overline{x}_{k}\\right)+\\widehat{e}_{i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, let $\\widehat{\\sigma}_{y}$ be the sample standard deviation for the dependent variable, let $\\widehat{\\sigma}_{1}$ be the sample sd for $x_{1}$, let $\\widehat{\\sigma}_{2}$ be the sample standard deviation, ```sd()```, for $x_{2}$, and so on. Then, simple algebra gives the equation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left(y_{i}-\\overline{y}\\right) / \\widehat{\\sigma}_{y} &=\\left(\\widehat{\\sigma}_{1} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{1}\\left[\\left(x_{i 1}-\\overline{x}_{1}\\right) / \\widehat{\\sigma}_{1}\\right]+\\ldots \\\\ &+\\left(\\widehat{\\sigma}_{k} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{k}\\left[\\left(x_{i k}-\\overline{x}_{k}\\right) / \\widehat{\\sigma}_{k}\\right]+\\left(\\widehat{e}_{i} / \\widehat{\\sigma}_{y}\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now define $z_{i y}=\\left(y_{i}-\\overline{y}\\right) / \\widehat{\\sigma}_{y}$, $z_{i l}=\\left[\\left(x_{i l}-\\overline{x}_{l}\\right) / \\widehat{\\sigma}_{l}\\right]$, $\\widehat{b}_{l}=\\left(\\widehat{\\sigma}_{l} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{l}$ for $l=1,\\ldots,k$, and $\\widehat{\\varepsilon}_i=\\left(\\widehat{e}_{i} / \\widehat{\\sigma}_{y}\\right)$. Then\n",
    "\n",
    "$$\n",
    "z_{y}=\\widehat{b}_{1} z_{1}+\\widehat{b}_{2} z_{2}+\\ldots+\\widehat{b}_{k} z_{k}+\\widehat{\\varepsilon}_i.\n",
    "$$\n",
    "\n",
    "The new coefficients are\n",
    "\n",
    "$$\n",
    "\\widehat{b}_{j}=\\left(\\widehat{\\sigma}_{j} / \\widehat{\\sigma}_{y}\\right) \\widehat{\\beta}_{j} \\text { for } j=1, \\ldots, k.\n",
    "$$\n",
    "\n",
    "These $\\widehat{b}_{j}$ are traditionally called **standardized coefficients** or **beta coefficients**.\n",
    "\n",
    "âœðŸ½ If $x_l$ increases by one standard deviation, then $\\widehat{y}$ changes by $\\widehat{b}_l$ standard deviations. Thus, *we are measuring effects not in terms of the original units of $y$ or the $x_l$, but in standard deviation units*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## installing the 'lm.beta' package if not previously installed\n",
    "if (!require(lm.beta)) install.packages('lm.beta')\n",
    "\n",
    "lm.beta(ols.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ðŸ’» Since each $x_l$ have been standardized, comparing the _magnitudes_ of the resulting beta coefficients is now useful. The ```age``` of the house seems to have the largest effect on the price of a home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ins>Pre-Processing in Machine Learning</ins>: In machine learning, standardizing (*re-centering* and *scaling*) predictors is commonly done before model fitting. No transformation is usually done to the outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X1 <- model.matrix(ols.1)[,-1]\n",
    "datos <- cbind(data.frame(lprice=hprice3$lprice),as.data.frame(X1))\n",
    "\n",
    "## installing the 'caret' package if not previously installed\n",
    "if (!require(caret)) install.packages('caret')\n",
    "\n",
    "modelo <- train(lprice ~ .,\n",
    "               data = datos,\n",
    "               method = \"lm\",\n",
    "               preProcess = c('scale', 'center')\n",
    "               )\n",
    "\n",
    "coef(modelo$finalModel)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
